{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# COGS 118B - Final Project\n",
        "\n",
        "## Reinforcement Learning & OpenAI Gym for Playable Pokemon Battle AI Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Group members\n",
        "\n",
        "- Karun Mokha\n",
        "- Ke Zhang\n",
        "- Pranjli Khana"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Abstract \n",
        "Our project aims to develop an AI agent capable of competitively playing Pokemon battles at varying levels of difficulty. We will leverage OpenAI Gym to create a battle environment, using existing battle simulators to focus on AI development rather than game mechanics. The agent will be trained using Reinforcement Learning (RL), Monte Carlo Search Tree (MCTS), or Proximal Policy Optimization (PPO), evaluating potential outcomes each turn to refine strategy. Performance will be measured through win rates against different opponents, effectiveness of moves, and adaptability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Background\n",
        "\n",
        "The Pokemon series began in 1996 with the release of Pokemon Red, Blue, and Yellow. Initial AI opponents in these games used simple, rule-based strategies. Advancements in AI have since enabled more complex strategies in games like chess, Go, and Dota 2. Applying these to Pokemon battles presents unique challenges due to the game's mechanics such as type advantages and turn-based strategies. Recent projects, like the Stanford University initiative, have used MCTS in developing AI for Pokemon battles, demonstrating the feasibility of advanced strategic AI in this context.[<sup>1</sup>](#ref1)\n",
        "\n",
        "Our work builds upon these advancements, aiming to enhance the AI's adaptability and strategic depth using cutting-edge AI techniques."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Problem Statement\n",
        "\n",
        "The challenge is to develop an AI agent that can competitively engage in Pokemon battles across different difficulty levels. The AI must efficiently use RL, MCTS, or PPO to make strategic decisions during battles to maximize victory chances. The solution involves quantifiable, measurable, and replicable approaches, using a well-defined state and action representation of the game."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data\n",
        "\n",
        "We are utilizing datasets from Kaggle which provide detailed statistics on Pokemon and combat outcomes. These datasets will help in modeling realistic battle scenarios and training the AI. The datasets include:\n",
        "- Pokemon Dataset with Team Combat: Comprehensive data on individual and team battles.[<sup>2</sup>](#ref2)\n",
        "- Pokemon with Stats: Detailed attributes of each Pokemon which are essential for AI training and strategy development.[<sup>3</sup>](#ref3)\n",
        "\n",
        "Data preprocessing involves cleaning duplicates, normalizing data, and encoding categorical variables like type matchups."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Proposed Solution\n",
        "\n",
        "Our approach involves developing an AI using MCTS and RL to navigate the complex decision-making process in Pokemon battles. The solution includes a detailed state representation of the game, a defined action space, and a reward function tailored to encourage strategic depth and adaptability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluation Metrics\n",
        "\n",
        "The AI's performance will be assessed through metrics like win rate, move effectiveness, and adaptability against varied opponents. These metrics will help quantify the effectiveness of the AI in real battle scenarios and against benchmark models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Discussion\n",
        "\n",
        "This section will analyze the results, discussing the effectiveness of our AI in achieving strategic gameplay in Pokemon battles. We will also address potential ethical and privacy concerns related to the use of game data and AI in public domains."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Footnotes\n",
        "<a name=\"ref1\"></a>1. Burkett, Tibrewala, Zhang (2021). Monte Carlo Tree Search for Competitive Pokemon Battling. Stanford University.\n",
        "<a name=\"ref2\"></a>2. Nguyen Van Anh, T. Pokemon Dataset with Team Combat. Retrieved from https://www.kaggle.com/datasets/tuannguyenvananh/pokemon-dataset-with-team-combat.\n",
        "<a name=\"ref3\"></a>3. Barradas, A. Pokemon with stats. Retrieved from https://www.kaggle.com/datasets/abcsds/pokemon/data."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
