{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# COGS 188 - Project Proposal\n",
        "## Using Reinforcement Learning & OpenAI Gym to Build a Playable Pokemon Battle AI Agent\n",
        "\n",
        "### Names\n",
        "- Karun Mokha\n",
        "- Ke Zhang\n",
        "- Pranjli Khana"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Abstract\n",
        "Our project aims to develop an AI agent capable of competitively playing Pokemon battles at varying levels of difficulty. We will create a battle environment within OpenAI Gym, leveraging existing open source battle simulators to focus on developing and tuning our AI and not get bogged down by the intricacies of the game mechanics. Using AI to simulate numerous possible battle sequences can help the AI learn and determine the best move and strategy to maximize the odds of winning. We plan to use techniques like RL, Monte Carlo Search Tree, or Proximal Policy Optimization, where the AI evaluates potential outcomes each turn during battle and refines its strategy based on simulation. Performance will be measured through the AI’s win rate in a fixed number of test battles against scripted and human opponents, the number of moves chosen by the AI which are super effective against the opponent, and adaptability-measured by the change in win rate against different scripted opponents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Background\n",
        "Since Pokémon’s video game debut in 1996 with Pokémon Red, Blue, and Yellow on the Game Boy, players have encountered AI opponents. These early AIs followed simple rule-based strategies to select moves and switch Pokémon, providing a baseline level of challenge. Over the years, advancements in AI game playing have been significant, with achievements in complex games like chess, Go, and Dota 2. Notably, DeepMind's AlphaGo combined deep neural networks with Monte Carlo Tree Search (MCTS) to master Go. Similarly, OpenAI's agents have played Dota 2 at competitive levels using reinforcement learning techniques. Applying such advanced AI techniques to Pokémon battles introduces challenges due to unique game mechanics like type advantages and turn-based strategies. Recent projects, including a Stanford University project, have used MCTS for Pokémon battles, showing that AI can adapt strategies based on game states and outcomes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Problem Statement\n",
        "The primary challenge is to develop an AI agent that can play Pokémon battles competitively at varying difficulty levels. The problem is multifaceted, involving the creation of an AI that can make strategic decisions during battles to maximize winning chances. This involves quantifiable measures through the state representation of battles, the action space available to the AI, and a reward function to guide its learning. The solution must be measurable, replicable, and capable of being trained repeatedly within the OpenAI Gym environment to ensure the robustness and reproducibility of the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data\n",
        "We are using datasets from Kaggle for our AI training. These datasets include detailed Pokémon statistics and battle outcomes which provide a foundation for realistic and competitive AI training:\n",
        "- **Pokemon Dataset with Team Combat**: Contains individual Pokémon statistics and their performance in team combats.\n",
        "- **Pokemon with Stats**: Provides comprehensive data on Pokémon attributes affecting their performance in battles. \n",
        "Data preparation involves cleaning, normalization, and feature engineering to ensure the AI can effectively learn and make decisions based on this data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Proposed Solution\n",
        "Our approach is to develop an AI using Monte Carlo Tree Search (MCTS) and Reinforcement Learning (RL) to navigate Pokémon battles strategically. This involves state representation of each game scenario, defining the action space for AI moves, and designing a reward function that promotes effective strategy development. We will implement the Proximal Policy Optimization algorithm, optimizing the AI’s decision-making process and ensuring its ability to adapt to various opponents and battle conditions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ethics & Privacy\n",
        "We consider the ethical implications of AI in gameplay, focusing on ensuring data privacy, mitigating bias in AI training, and promoting fairness and transparency in AI decisions. We commit to ethical AI development practices, including the responsible use of data and adherence to privacy laws to protect the information of all involved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Team Expectations\n",
        "We expect all team members to contribute equally, maintain open communication, and adhere to project timelines. Regular meetings will ensure each member is on track and any issues are promptly addressed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Project Timeline\n",
        "We have outlined a detailed timeline for our project, from initial research and data collection through to the final testing and presentation of our AI agent. This structured approach will help us manage our time effectively and ensure all project milestones are met."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Footnotes\n",
        "- DeepMind's AlphaGo: Nature, 2016.\n",
        "- OpenAI's Dota 2 AI: OpenAI, 2018.\n",
        "- Pokemon Dataset: Kaggle.\n",
        "- Stanford AI Project: Stanford University, 2021."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
